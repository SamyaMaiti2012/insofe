{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-23T10:06:28.929418Z",
     "start_time": "2019-03-23T10:06:28.925182Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
      "env: CUDA_VISIBLE_DEVICES=1\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "%env CUDA_VISIBLE_DEVICES=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-23T10:06:33.351591Z",
     "start_time": "2019-03-23T10:06:28.936170Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.25)\n",
    "sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-23T10:06:33.735635Z",
     "start_time": "2019-03-23T10:06:33.354192Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "from keras.datasets import cifar10\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Flatten, Dense, Dropout\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.layers import BatchNormalization, GlobalAveragePooling2D\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "\n",
    "# Get Inception architecture from keras.applications\n",
    "from keras.applications.inception_v3 import InceptionV3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-23T10:06:33.743659Z",
     "start_time": "2019-03-23T10:06:33.737196Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_cifar10(resize=False):\n",
    "    train = np.load('/nfsroot/data/home/datasets/cse_7321c/cifar10/cifar_train.npz')\n",
    "    x_train = train['data']\n",
    "    y_train = train['labels']\n",
    "\n",
    "    test = np.load('/nfsroot/data/home/datasets/cse_7321c/cifar10cifar_test.npz')\n",
    "    x_test = test['data']\n",
    "    y_test = test['labels']\n",
    "    \n",
    "    if resize:\n",
    "        x_train=resize_all(x_train, resize)\n",
    "        x_test=resize_all(x_test, resize)\n",
    "    \n",
    "    x_train = x_train.astype('float32')/255.\n",
    "    x_test = x_test.astype('float32')/255.\n",
    "    \n",
    "    return(x_train, y_train, x_test, y_test)\n",
    "\n",
    "\n",
    "def resize(p, size):\n",
    "    return Image.fromarray(p).resize(size=(size,size))\n",
    "\n",
    "def resize_all(arr, size):\n",
    "    t = []\n",
    "    for i in range(arr.shape[0]):\n",
    "        t.append(np.array(resize(arr[i], size)))\n",
    "        \n",
    "#     t = np.array(t, dtype='float32')\n",
    "#     t /= 255.\n",
    "\n",
    "    return(np.array(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-23T10:06:33.749136Z",
     "start_time": "2019-03-23T10:06:33.746341Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "nb_classes = 10\n",
    "\n",
    "img_rows, img_cols = 32, 32    # input image dimensions\n",
    "img_channels = 3               # The CIFAR10 images are RGB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-03-23T10:06:29.011Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      " 36446208/170498071 [=====>........................] - ETA: 5:43"
     ]
    }
   ],
   "source": [
    "(x_train, train_labels), (x_test, test_labels) = cifar10.load_data()\n",
    "x_train = x_train.astype('float32')/255.\n",
    "x_test = x_test.astype('float32')/255.\n",
    "\n",
    "y_train = to_categorical(train_labels, nb_classes)\n",
    "y_test = to_categorical(test_labels, nb_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot a few train images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-03-23T10:06:29.079Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "for i in range(5):\n",
    "    plt.subplot(1,5,i+1)\n",
    "    plt.imshow(x_train[i])\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-03-23T10:06:29.144Z"
    }
   },
   "outputs": [],
   "source": [
    "def custom_convnet(nb_classes, learn_rate, inp_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Convolution2D(filters=32, kernel_size=(3, 3), padding='same', # valid\n",
    "                            input_shape=inp_shape, \n",
    "                            activation='relu'))\n",
    "    model.add(Convolution2D(filters=32, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Convolution2D(filters=64, kernel_size=(3, 3), padding='same', activation='relu'))\n",
    "    model.add(Convolution2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(nb_classes, activation='softmax'))\n",
    "    \n",
    "    adam = Adam(lr=learn_rate)\n",
    "    model.compile(loss='categorical_crossentropy',metrics=['accuracy'],optimizer=adam)\n",
    "    \n",
    "    return(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a lot of samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-03-23T10:06:29.206Z"
    }
   },
   "outputs": [],
   "source": [
    "model = custom_convnet(nb_classes=10, learn_rate=0.001, inp_shape=(img_rows,img_cols,img_channels))\n",
    "model.fit(x_train[:50000], y_train[:50000],\n",
    "          validation_data=(x_test, y_test),\n",
    "          batch_size=batch_size,\n",
    "          epochs=5)\n",
    "\n",
    "model.save('cifar10_savedmodel.h5')          # Saves the weights along with the graph\n",
    "# model.save_weights('cifar10_savedmodel.h5')  # Saves the weights only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With limited samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-03-23T10:06:29.272Z"
    }
   },
   "outputs": [],
   "source": [
    "model = custom_convnet(nb_classes=10, learn_rate=0.001, inp_shape=(img_rows,img_cols,img_channels))\n",
    "model.fit(x_train[:5000], y_train[:5000],\n",
    "          validation_data=(x_test, y_test),\n",
    "          batch_size=batch_size,\n",
    "          epochs=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Trained Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resize all the images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-03-23T10:06:29.398Z"
    }
   },
   "outputs": [],
   "source": [
    "(x_train, train_labels), (x_test, test_labels) = cifar10.load_data()\n",
    "size=224\n",
    "x_train=resize_all(x_train, size)\n",
    "x_test=resize_all(x_test, size)\n",
    "\n",
    "x_train = x_train.astype('float32')/255.\n",
    "x_test = x_test.astype('float32')/255.\n",
    "\n",
    "y_train = to_categorical(train_labels, nb_classes)\n",
    "y_test = to_categorical(test_labels, nb_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-03-23T10:06:29.402Z"
    }
   },
   "outputs": [],
   "source": [
    "def inception_tl(nb_classes, freez_wts=True, learn_rate=0.001):\n",
    "    trained_model = InceptionV3(include_top=False,weights='imagenet')\n",
    "    x = trained_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    pred_inception= Dense(nb_classes,activation='softmax')(x)\n",
    "    model = Model(inputs=trained_model.input,outputs=pred_inception)\n",
    "    \n",
    "    for layer in trained_model.layers:\n",
    "        layer.trainable=(1-freez_wts)\n",
    "    \n",
    "    adam = Adam(lr=learn_rate)\n",
    "    model.compile(loss='categorical_crossentropy',metrics=['accuracy'],optimizer=adam)\n",
    "    \n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-03-23T10:06:29.404Z"
    }
   },
   "outputs": [],
   "source": [
    "model = inception_tl(nb_classes=nb_classes, freez_wts=True)\n",
    "model.fit(x_train[:5000], y_train[:5000],\n",
    "          validation_data=(x_test, y_test),\n",
    "          batch_size=batch_size,\n",
    "          epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
