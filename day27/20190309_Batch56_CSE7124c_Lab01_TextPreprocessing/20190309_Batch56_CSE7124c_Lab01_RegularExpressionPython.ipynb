{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-15T07:59:20.375174Z",
     "start_time": "2019-03-15T07:59:18.671821Z"
    }
   },
   "outputs": [],
   "source": [
    "# Regular expression\n",
    "import re\n",
    "import nltk\n",
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-15T07:59:20.391278Z",
     "start_time": "2019-03-15T07:59:20.388025Z"
    }
   },
   "outputs": [],
   "source": [
    "# raw = \" Get Data from wiki and print it on the screen\"\n",
    "raw = '''International School of Engineering (INSOFE) is an Applied Engineering school with area of focus in Data science/Big data analytics. It is located in Hyderabad in the state of Telangana, India, and Bengaluru in the state of Karnataka. It opened in 2011. \n",
    "The program is delivered through classroom only sessions and is suitable for students and working professionals. Dr. Dakshinamurthy V Kolluru, Dr. Sridhar Pappu and A S L Ganapathi Kumar started the institution in Hyderabad in mid-2011 and expanded to Bengaluru in early-2016. Initially the school functioned under mentorship of Dr. Dakshinamurthy, Dr. Sridhar and Dr. Sreerama Murthy. They are now supported by a team of additional mentors and in-house data scientists.\n",
    "The first cohort commenced in mid-2011 with 12 students. INSOFE has since trained over 2000 students from across the globe. In 2012, INSOFE also started corporate training services. It extended operations to Bengaluru in 2016.CIO.com listed INSOFE 3rd in their list of \"16 Big Data Certifications That Will Pay Off\" consecutively from 2013-2016.[2] Silicon India Magazine listed INSOFE in their list of \"Top 5 Big Data Training Institutes 2016\".[3] Analytics India Magazine, listed INSOFE in \"Top 9 Analytics Training Institutes in India in 2016\". KDnuggets mentioned INSOFE in their list of Certificates in Analytics, Data Mining, and Data Science in 2014.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-15T07:59:23.429816Z",
     "start_time": "2019-03-15T07:59:23.406366Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['International',\n",
       " 'School',\n",
       " 'of',\n",
       " 'Engineering',\n",
       " '(',\n",
       " 'INSOFE',\n",
       " ')',\n",
       " 'is',\n",
       " 'an',\n",
       " 'Applied',\n",
       " 'Engineering',\n",
       " 'school',\n",
       " 'with',\n",
       " 'area',\n",
       " 'of',\n",
       " 'focus',\n",
       " 'in',\n",
       " 'Data',\n",
       " 'science/Big',\n",
       " 'data',\n",
       " 'analytics',\n",
       " '.',\n",
       " 'It',\n",
       " 'is',\n",
       " 'located',\n",
       " 'in',\n",
       " 'Hyderabad',\n",
       " 'in',\n",
       " 'the',\n",
       " 'state',\n",
       " 'of',\n",
       " 'Telangana',\n",
       " ',',\n",
       " 'India',\n",
       " ',',\n",
       " 'and',\n",
       " 'Bengaluru',\n",
       " 'in',\n",
       " 'the',\n",
       " 'state',\n",
       " 'of',\n",
       " 'Karnataka',\n",
       " '.',\n",
       " 'It',\n",
       " 'opened',\n",
       " 'in',\n",
       " '2011',\n",
       " '.',\n",
       " 'The',\n",
       " 'program',\n",
       " 'is',\n",
       " 'delivered',\n",
       " 'through',\n",
       " 'classroom',\n",
       " 'only',\n",
       " 'sessions',\n",
       " 'and',\n",
       " 'is',\n",
       " 'suitable',\n",
       " 'for',\n",
       " 'students',\n",
       " 'and',\n",
       " 'working',\n",
       " 'professionals',\n",
       " '.',\n",
       " 'Dr.',\n",
       " 'Dakshinamurthy',\n",
       " 'V',\n",
       " 'Kolluru',\n",
       " ',',\n",
       " 'Dr.',\n",
       " 'Sridhar',\n",
       " 'Pappu',\n",
       " 'and',\n",
       " 'A',\n",
       " 'S',\n",
       " 'L',\n",
       " 'Ganapathi',\n",
       " 'Kumar',\n",
       " 'started',\n",
       " 'the',\n",
       " 'institution',\n",
       " 'in',\n",
       " 'Hyderabad',\n",
       " 'in',\n",
       " 'mid-2011',\n",
       " 'and',\n",
       " 'expanded',\n",
       " 'to',\n",
       " 'Bengaluru',\n",
       " 'in',\n",
       " 'early-2016',\n",
       " '.',\n",
       " 'Initially',\n",
       " 'the',\n",
       " 'school',\n",
       " 'functioned',\n",
       " 'under',\n",
       " 'mentorship',\n",
       " 'of',\n",
       " 'Dr.',\n",
       " 'Dakshinamurthy',\n",
       " ',',\n",
       " 'Dr.',\n",
       " 'Sridhar',\n",
       " 'and',\n",
       " 'Dr.',\n",
       " 'Sreerama',\n",
       " 'Murthy',\n",
       " '.',\n",
       " 'They',\n",
       " 'are',\n",
       " 'now',\n",
       " 'supported',\n",
       " 'by',\n",
       " 'a',\n",
       " 'team',\n",
       " 'of',\n",
       " 'additional',\n",
       " 'mentors',\n",
       " 'and',\n",
       " 'in-house',\n",
       " 'data',\n",
       " 'scientists',\n",
       " '.',\n",
       " 'The',\n",
       " 'first',\n",
       " 'cohort',\n",
       " 'commenced',\n",
       " 'in',\n",
       " 'mid-2011',\n",
       " 'with',\n",
       " '12',\n",
       " 'students',\n",
       " '.',\n",
       " 'INSOFE',\n",
       " 'has',\n",
       " 'since',\n",
       " 'trained',\n",
       " 'over',\n",
       " '2000',\n",
       " 'students',\n",
       " 'from',\n",
       " 'across',\n",
       " 'the',\n",
       " 'globe',\n",
       " '.',\n",
       " 'In',\n",
       " '2012',\n",
       " ',',\n",
       " 'INSOFE',\n",
       " 'also',\n",
       " 'started',\n",
       " 'corporate',\n",
       " 'training',\n",
       " 'services',\n",
       " '.',\n",
       " 'It',\n",
       " 'extended',\n",
       " 'operations',\n",
       " 'to',\n",
       " 'Bengaluru',\n",
       " 'in',\n",
       " '2016.CIO.com',\n",
       " 'listed',\n",
       " 'INSOFE',\n",
       " '3rd',\n",
       " 'in',\n",
       " 'their',\n",
       " 'list',\n",
       " 'of',\n",
       " '``',\n",
       " '16',\n",
       " 'Big',\n",
       " 'Data',\n",
       " 'Certifications',\n",
       " 'That',\n",
       " 'Will',\n",
       " 'Pay',\n",
       " 'Off',\n",
       " \"''\",\n",
       " 'consecutively',\n",
       " 'from',\n",
       " '2013-2016',\n",
       " '.',\n",
       " '[',\n",
       " '2',\n",
       " ']',\n",
       " 'Silicon',\n",
       " 'India',\n",
       " 'Magazine',\n",
       " 'listed',\n",
       " 'INSOFE',\n",
       " 'in',\n",
       " 'their',\n",
       " 'list',\n",
       " 'of',\n",
       " '``',\n",
       " 'Top',\n",
       " '5',\n",
       " 'Big',\n",
       " 'Data',\n",
       " 'Training',\n",
       " 'Institutes',\n",
       " '2016',\n",
       " \"''\",\n",
       " '.',\n",
       " '[',\n",
       " '3',\n",
       " ']',\n",
       " 'Analytics',\n",
       " 'India',\n",
       " 'Magazine',\n",
       " ',',\n",
       " 'listed',\n",
       " 'INSOFE',\n",
       " 'in',\n",
       " '``',\n",
       " 'Top',\n",
       " '9',\n",
       " 'Analytics',\n",
       " 'Training',\n",
       " 'Institutes',\n",
       " 'in',\n",
       " 'India',\n",
       " 'in',\n",
       " '2016',\n",
       " \"''\",\n",
       " '.',\n",
       " 'KDnuggets',\n",
       " 'mentioned',\n",
       " 'INSOFE',\n",
       " 'in',\n",
       " 'their',\n",
       " 'list',\n",
       " 'of',\n",
       " 'Certificates',\n",
       " 'in',\n",
       " 'Analytics',\n",
       " ',',\n",
       " 'Data',\n",
       " 'Mining',\n",
       " ',',\n",
       " 'and',\n",
       " 'Data',\n",
       " 'Science',\n",
       " 'in',\n",
       " '2014',\n",
       " '.']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ed|ing|s\tMatches one of the specified strings (disjunction)\n",
    "# Tokenize the data\n",
    "tokens = word_tokenize(raw)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-15T07:59:44.783718Z",
     "start_time": "2019-03-15T07:59:44.779185Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['INSOFE',\n",
       " 'the',\n",
       " 'state',\n",
       " 'the',\n",
       " 'state',\n",
       " 'The',\n",
       " 'suitable',\n",
       " 'the',\n",
       " 'the',\n",
       " 'are',\n",
       " 'in-house',\n",
       " 'The',\n",
       " 'INSOFE',\n",
       " 'since',\n",
       " 'the',\n",
       " 'globe',\n",
       " 'INSOFE',\n",
       " 'corporate',\n",
       " 'INSOFE',\n",
       " 'Magazine',\n",
       " 'INSOFE',\n",
       " 'Magazine',\n",
       " 'INSOFE',\n",
       " 'INSOFE',\n",
       " 'Science']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 'e$|E$'\tMatches some pattern e or E at the end of a string\n",
    "[w for w in tokens if re.search('e$|E$', w)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-15T08:00:38.708472Z",
     "start_time": "2019-03-15T08:00:38.703745Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.',\n",
       " '.',\n",
       " '.',\n",
       " '.',\n",
       " 'Dr.',\n",
       " 'Dr.',\n",
       " 'mid-2011',\n",
       " 'early-2016',\n",
       " '.',\n",
       " 'Dr.',\n",
       " 'Dr.',\n",
       " 'Dr.',\n",
       " '.',\n",
       " 'in-house',\n",
       " '.',\n",
       " 'mid-2011',\n",
       " '.',\n",
       " '.',\n",
       " '.',\n",
       " '2016.CIO.com',\n",
       " '2013-2016',\n",
       " '.',\n",
       " '.',\n",
       " '.',\n",
       " '.']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[w for w in tokens if re.search('[.-]', w)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-15T08:01:18.950592Z",
     "start_time": "2019-03-15T08:01:18.946434Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['area',\n",
       " 'Data',\n",
       " 'data',\n",
       " 'Telangana',\n",
       " 'India',\n",
       " 'Karnataka',\n",
       " 'Sreerama',\n",
       " 'a',\n",
       " 'data',\n",
       " 'Data',\n",
       " 'India',\n",
       " 'Data',\n",
       " 'India',\n",
       " 'India',\n",
       " 'Data',\n",
       " 'Data']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Match pattern that has the character a and ends with a\n",
    "[w for w in tokens if re.search('a*a$', w)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-15T08:01:22.388890Z",
     "start_time": "2019-03-15T08:01:22.384449Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Match pattern starting with mo\n",
    "[w for w in tokens if re.search('^mo', w)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-15T08:01:22.898430Z",
     "start_time": "2019-03-15T08:01:22.893920Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Telangana', 'Karnataka']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# .\tWildcard, matches any character\n",
    "# Returns words with j as its third letter and t as its sixth letter.\n",
    "[w for w in tokens if re.search('^[TK].....a.a', w)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Difference between '*' and '?'\n",
    "'\\*' - Causes the resulting RE to match 0 or more repetitions of the preceding RE, as many repetitions as are possible. ab* will match ‘a’, ‘ab’, or ‘a’ followed by any number of ‘b’s.\n",
    "\n",
    "'?' - Causes the resulting RE to match 0 or 1 repetitions of the preceding RE. ab? will match either ‘a’ or ‘ab’.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-15T08:02:32.756229Z",
     "start_time": "2019-03-15T08:02:32.753241Z"
    }
   },
   "outputs": [],
   "source": [
    "c = ['color', 'colour', 'colouur']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-15T08:02:45.570227Z",
     "start_time": "2019-03-15T08:02:45.565981Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['color', 'colour']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[w for w in c if re.search('colou?r', w)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-15T08:02:45.954115Z",
     "start_time": "2019-03-15T08:02:45.949733Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['color', 'colour', 'colouur']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[w for w in c if re.search('colou*r', w)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-15T08:02:48.159565Z",
     "start_time": "2019-03-15T08:02:48.155255Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['area']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The first part of the expression, «^[abc]», \n",
    "# matches the start of a word followed by a, b, or c. \n",
    "# The next part of the expression, «[pqr]», \n",
    " # constrains the second character to be p, q, or r. \n",
    "# The third and fourth characters are also constrained. \n",
    "# Only four words satisfy all these constraints.\n",
    "# fourth word whould end with a,b or c\n",
    "# [abc]\tMatches one of a set of characters\n",
    "[w for w in tokens if re.search('^[abc][pqr][edf][abc]$', w)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-15T08:03:06.719863Z",
     "start_time": "2019-03-15T08:03:06.715367Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Karnataka']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# +\tOne or more of previous item, e.g. a+, [a-z]+\n",
    "[w for w in tokens if re.search('^K.......a$', w)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-15T08:03:09.151511Z",
     "start_time": "2019-03-15T08:03:09.146875Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Karnataka', 'Kolluru', 'Kumar', 'KDnuggets']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[w for w in tokens if re.search('^K', w)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-15T08:03:20.379991Z",
     "start_time": "2019-03-15T08:03:20.375601Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Karnataka']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[w for w in tokens if re.search('(^Kar).*(ka$)', w)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-15T08:03:27.455295Z",
     "start_time": "2019-03-15T08:03:27.450695Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2011',\n",
       " '12',\n",
       " '2000',\n",
       " '2012',\n",
       " '2016.CIO.com',\n",
       " '3rd',\n",
       " '16',\n",
       " '2013-2016',\n",
       " '2',\n",
       " '5',\n",
       " '2016',\n",
       " '3',\n",
       " '9',\n",
       " '2016',\n",
       " '2014']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [A-Z0-9]\tMatches one of a range of characters\n",
    "#[w for w in tokens if re.search('^[0-9]+\\.[0-9]+\\.[0-9]+$', w)]\n",
    "[w for w in tokens if re.search('^[0-9]', w)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-15T08:04:10.994831Z",
     "start_time": "2019-03-15T08:04:10.990040Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['INSOFE',\n",
       " 'V',\n",
       " 'A',\n",
       " 'S',\n",
       " 'L',\n",
       " 'INSOFE',\n",
       " 'INSOFE',\n",
       " 'INSOFE',\n",
       " 'INSOFE',\n",
       " 'INSOFE',\n",
       " 'INSOFE']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[w for w in tokens if re.search('^[A-Z]+$', w)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-15T08:04:11.168233Z",
     "start_time": "2019-03-15T08:04:11.165948Z"
    }
   },
   "outputs": [],
   "source": [
    "tk1 = ['test', '234-insofe','2-insfe', '26555-insf', '23-in', '24-ins', 'insofe-in-ind']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-15T08:04:38.726640Z",
     "start_time": "2019-03-15T08:04:38.722286Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2-insfe', '26555-insf', '24-ins']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# {n}\tExactly n repeats where n is a non-negative integer\n",
    "#{n,}\tAt least n repeats\n",
    "# {,n}\tNo more than n repeats\n",
    "# {m,n}\tAt least m and no more than n repeats\n",
    "[w for w in tk1 if re.search('^[0-9]+-[a-z]{3,5}$', w)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-15T08:04:57.416363Z",
     "start_time": "2019-03-15T08:04:57.411933Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['insofe-in-ind']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[w for w in tk1 if re.search('^[a-z]{5,}-[a-z]{2,3}-[a-z]{,6}$', w)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-15T08:06:51.813086Z",
     "start_time": "2019-03-15T08:06:51.808738Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Engineering',\n",
       " 'Applied',\n",
       " 'Engineering',\n",
       " 'located',\n",
       " 'opened',\n",
       " 'delivered',\n",
       " 'working',\n",
       " 'started',\n",
       " 'expanded',\n",
       " 'functioned',\n",
       " 'supported',\n",
       " 'commenced',\n",
       " 'trained',\n",
       " 'started',\n",
       " 'training',\n",
       " 'extended',\n",
       " 'listed',\n",
       " 'listed',\n",
       " 'Training',\n",
       " 'listed',\n",
       " 'Training',\n",
       " 'mentioned',\n",
       " 'Mining']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a(b|c)+\tParentheses that indicate the scope of the operators\n",
    "[w for w in tokens if re.search('(ed|ing)$', w)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding Vowels in a String"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-15T09:33:18.487285Z",
     "start_time": "2019-03-15T09:33:18.454049Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['u',\n",
       " 'e',\n",
       " 'a',\n",
       " 'i',\n",
       " 'a',\n",
       " 'i',\n",
       " 'i',\n",
       " 'i',\n",
       " 'e',\n",
       " 'i',\n",
       " 'a',\n",
       " 'i',\n",
       " 'o',\n",
       " 'i',\n",
       " 'o',\n",
       " 'u']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word = 'supercalifragilisticexpialidocious'\n",
    "# finds all (non-overlapping) matches of the given regular expression \n",
    "re.findall('[aeiou]', word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-15T09:33:33.227683Z",
     "start_time": "2019-03-15T09:33:33.202413Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Text: Exasperating farrago of distortions , misrepresentations and outright...>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Text\n",
    "#moby = nltk.Text(word_tokenize(\"\"\"It is easy to build search patterns when the linguistic phenomenon were \n",
    "#studying is tied to particular words\"\"\"))\n",
    "\n",
    "moby = nltk.Text(word_tokenize(\"\"\"Exasperating farrago of distortions, misrepresentations and \n",
    "outright lies being broadcast by an unprincipled showman masquerading as a journalist\"\"\"))\n",
    "\n",
    "moby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-15T09:36:44.638422Z",
     "start_time": "2019-03-15T09:36:44.632172Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outright\n"
     ]
    }
   ],
   "source": [
    "# xt. The angle brackets are used to mark token boundaries\n",
    "# <.*> which will match any single token, and enclose it in parentheses so only the matched word \n",
    "moby.findall('<and>(<.*>)<lies>')\n",
    "# nltk.Text(word_tokenize(\"build sample 1 patterns\")).findall(r'<build> (<.*>+) <patterns>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-15T09:36:45.637064Z",
     "start_time": "2019-03-15T09:36:45.633646Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distortions , misrepresentations and outright lies being broadcast by\n"
     ]
    }
   ],
   "source": [
    "moby.findall('<of> (<.*>+) <an>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-15T09:37:04.872706Z",
     "start_time": "2019-03-15T09:37:04.867957Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "an unprincipled showman\n"
     ]
    }
   ],
   "source": [
    "# finds three-word phrases ending with the word showman\n",
    "moby.findall('<.*> <.*> <showman>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-15T09:37:08.796105Z",
     "start_time": "2019-03-15T09:37:08.792688Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exasperating farrago of distortions\n"
     ]
    }
   ],
   "source": [
    "#  searching a large text corpus for expressions of the form x and other ys allows\n",
    "moby.findall(\"<.*> <farrago> <of> <.*>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-15T09:37:10.423181Z",
     "start_time": "2019-03-15T09:37:10.420609Z"
    }
   },
   "outputs": [],
   "source": [
    "raw = \"\"\"'When I'M a Duchess,' she said to herself, (not in a very hopeful tone\n",
    "    though),      'I won't have any pepper in my kitchen AT ALL. Soup does very\n",
    "    well without bread-and-butter--Maybe it's always pepper that makes people hot-tempered,dejected'...\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-15T09:38:04.446700Z",
     "start_time": "2019-03-15T09:38:04.442643Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"'When\",\n",
       " \"I'M\",\n",
       " 'a',\n",
       " \"Duchess,'\",\n",
       " 'she',\n",
       " 'said',\n",
       " 'to',\n",
       " 'herself,',\n",
       " '(not',\n",
       " 'in',\n",
       " 'a',\n",
       " 'very',\n",
       " 'hopeful',\n",
       " 'tone\\n',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'though),',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " \"'I\",\n",
       " \"won't\",\n",
       " 'have',\n",
       " 'any',\n",
       " 'pepper',\n",
       " 'in',\n",
       " 'my',\n",
       " 'kitchen',\n",
       " 'AT',\n",
       " 'ALL.',\n",
       " 'Soup',\n",
       " 'does',\n",
       " 'very\\n',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'well',\n",
       " 'without',\n",
       " 'bread-and-butter--Maybe',\n",
       " \"it's\",\n",
       " 'always',\n",
       " 'pepper',\n",
       " 'that',\n",
       " 'makes',\n",
       " 'people',\n",
       " \"hot-tempered,dejected'...\"]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Splittiing the raw text on whitespace using raw.split()\n",
    "re.split(r' ', raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-15T09:38:09.142097Z",
     "start_time": "2019-03-15T09:38:09.137605Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"'When\",\n",
       " \"I'M\",\n",
       " 'a',\n",
       " \"Duchess,'\",\n",
       " 'she',\n",
       " 'said',\n",
       " 'to',\n",
       " 'herself,',\n",
       " '(not',\n",
       " 'in',\n",
       " 'a',\n",
       " 'very',\n",
       " 'hopeful',\n",
       " 'tone',\n",
       " 'though),',\n",
       " \"'I\",\n",
       " \"won't\",\n",
       " 'have',\n",
       " 'any',\n",
       " 'pepper',\n",
       " 'in',\n",
       " 'my',\n",
       " 'kitchen',\n",
       " 'AT',\n",
       " 'ALL.',\n",
       " 'Soup',\n",
       " 'does',\n",
       " 'very',\n",
       " 'well',\n",
       " 'without',\n",
       " 'bread-and-butter--Maybe',\n",
       " \"it's\",\n",
       " 'always',\n",
       " 'pepper',\n",
       " 'that',\n",
       " 'makes',\n",
       " 'people',\n",
       " \"hot-tempered,dejected'...\"]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To split tokens that contain a \\n newline character; instead\n",
    "# we need to match any number of spaces, tabs, or newlines\n",
    "# The regular expression «[ \\t\\n]+» matches one or more space, tab (\\t) or newline (\\n)\n",
    "re.split('[ \\t\\n]+', raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-15T09:38:20.687509Z",
     "start_time": "2019-03-15T09:38:20.679071Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " 'When',\n",
       " 'I',\n",
       " 'M',\n",
       " 'a',\n",
       " 'Duchess',\n",
       " 'she',\n",
       " 'said',\n",
       " 'to',\n",
       " 'herself',\n",
       " 'not',\n",
       " 'in',\n",
       " 'a',\n",
       " 'very',\n",
       " 'hopeful',\n",
       " 'tone',\n",
       " 'though',\n",
       " 'I',\n",
       " 'won',\n",
       " 't',\n",
       " 'have',\n",
       " 'any',\n",
       " 'pepper',\n",
       " 'in',\n",
       " 'my',\n",
       " 'kitchen',\n",
       " 'AT',\n",
       " 'ALL',\n",
       " 'Soup',\n",
       " 'does',\n",
       " 'very',\n",
       " 'well',\n",
       " 'without',\n",
       " 'bread',\n",
       " 'and',\n",
       " 'butter',\n",
       " 'Maybe',\n",
       " 'it',\n",
       " 's',\n",
       " 'always',\n",
       " 'pepper',\n",
       " 'that',\n",
       " 'makes',\n",
       " 'people',\n",
       " 'hot',\n",
       " 'tempered',\n",
       " 'dejected',\n",
       " '']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To get only the words from the text  \n",
    "# Python provides us with a character class \\w for word characters, equivalent to [a-zA-Z0-9_]\n",
    "re.split('\\W+', raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reference:\n",
    "    \n",
    "    https://docs.python.org/2/library/re.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
