{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create SPARK_HOME and PYLIB env var and update PATH env var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "os.environ[\"SPARK_HOME\"] = \"/usr/hdp/current/spark2-client\"\n",
    "os.environ[\"PYLIB\"] = os.environ[\"SPARK_HOME\"] + \"/python/lib\"\n",
    "sys.path.insert(0, os.environ[\"PYLIB\"] + \"/py4j-0.10.6-src.zip\")\n",
    "sys.path.insert(0, os.environ[\"PYLIB\"] + \"/pyspark.zip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build __SparkConf__ object \n",
    "\n",
    "    Contains information about your application.  \n",
    "\n",
    "\n",
    "Create __SparkContext__ object \n",
    "    \n",
    "    Tells Spark how to access a cluster. \n",
    "    \n",
    "\n",
    "Create __SparkSession__ object\n",
    "\n",
    "    The entry point to programming Spark with the Dataset and DataFrame API.\n",
    "\n",
    "    Used to create DataFrame, register DataFrame as tables and execute SQL over tables etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.conf import SparkConf\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "conf = SparkConf().setAppName(\"Universal Bank Data Set\").setMaster('local[*]')\n",
    "sc = SparkContext(conf=conf)\n",
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Loading the dependent libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "from pyspark.sql.functions import isnan, when, count, col, countDistinct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Problem Statement\n",
    "The dataset is from a bank, data related to direct marketing campaigns of a Portuguese banking institution. The marketing campaigns were based on phone calls. Often, more than one contact to the same client was required, to access if the product (bank term deposit) would be (or not) subscribed. The data and attribute description are in the folder. \n",
    "\n",
    "\n",
    "#### Data Dictionary\n",
    " The dataset has the following attributes:\n",
    "\n",
    "1 - age (numeric)\n",
    "\n",
    "2 - job : type of job (categorical: \"admin.\",\"unknown\",\"unemployed\",\"management\",\"housemaid\",\"entrepreneur\",\"student\",\n",
    "                                    \"blue-collar\",\"self-employed\",\"retired\",\"technician\",\"services\") \n",
    "\n",
    "3 - marital : marital status (categorical: \"married\",\"divorced\",\"single\"; note: \"divorced\" means divorced or widowed)\n",
    "\n",
    "4 - education (categorical: \"unknown\",\"secondary\",\"primary\",\"tertiary\")\n",
    "\n",
    "5 - default: has credit in default? (binary: \"yes\",\"no\")\n",
    "\n",
    "#### 6 - balance: average yearly balance, in euros (numeric) \n",
    "\n",
    "7 - housing: has housing loan? (binary: \"yes\",\"no\")\n",
    "\n",
    "8 - loan: has personal loan? (binary: \"yes\",\"no\")\n",
    "\n",
    "9 - contact: contact communication type (categorical: \"unknown\",\"telephone\",\"cellular\") \n",
    "\n",
    "10 - day: last contact day of the month (numeric)\n",
    "\n",
    "11 - month: last contact month of year (categorical: \"jan\", \"feb\", \"mar\", ..., \"nov\", \"dec\")\n",
    "\n",
    "12 - duration: last contact duration, in seconds (numeric)\n",
    "\n",
    "13 - campaign: number of contacts performed during this campaign and for this client (numeric, includes last contact)\n",
    "\n",
    "14 - pdays: number of days that passed by after the client was last contacted from a previous campaign (numeric, -1 means client was not previously contacted)\n",
    "  \n",
    "15 - previous: number of contacts performed before this campaign and for this client (numeric)\n",
    "\n",
    "16 - poutcome: outcome of the previous marketing campaign (categorical: \"unknown\",\"other\",\"failure\",\"success\")\n",
    "\n",
    "17 - Approved_no_yes - has the client subscribed to a __term deposit?__ (binary: \"yes\",\"no\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the schema to the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define Schema\n",
    "bankDataSchema = StructType([\n",
    "    StructField(\"age\", IntegerType(), True),\n",
    "    StructField(\"job\", StringType(), True),\n",
    "    StructField(\"marital_status\", StringType(), True),\n",
    "    StructField(\"education\", StringType(), True),\n",
    "    StructField(\"default\", StringType(), True),\n",
    "    StructField(\"balance\", DoubleType(), True),\n",
    "    StructField(\"housing\", StringType(), True),\n",
    "    StructField(\"loan\", StringType(), True),        \n",
    "    StructField(\"contact\", StringType(), True),\n",
    "    StructField(\"day\", IntegerType(), True),\n",
    "    StructField(\"month\", StringType(), True),\n",
    "    StructField(\"duration\", DoubleType(), True),\n",
    "    StructField(\"campaign\", DoubleType(), True),\n",
    "    StructField(\"pdays\", DoubleType(), True),\n",
    "    StructField(\"previous\", DoubleType(), True),\n",
    "    StructField(\"poutcome\", StringType(), True),\n",
    "    StructField(\"Approved_no_yes\", StringType(), True)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the data and creating a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = spark.read.csv(path=\"file:///home/mahidharv/academics/Batch44/CSE7322c/20181013_Batch44_CSE7322c_SparkML_Classification_Lab/bank_data.csv\",\n",
    "                      header=False,\n",
    "                      schema=bankDataSchema,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print Schema\n",
    "\n",
    "Hint: Use printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- age: integer (nullable = true)\n",
      " |-- job: string (nullable = true)\n",
      " |-- marital_status: string (nullable = true)\n",
      " |-- education: string (nullable = true)\n",
      " |-- default: string (nullable = true)\n",
      " |-- balance: double (nullable = true)\n",
      " |-- housing: string (nullable = true)\n",
      " |-- loan: string (nullable = true)\n",
      " |-- contact: string (nullable = true)\n",
      " |-- day: integer (nullable = true)\n",
      " |-- month: string (nullable = true)\n",
      " |-- duration: double (nullable = true)\n",
      " |-- campaign: double (nullable = true)\n",
      " |-- pdays: double (nullable = true)\n",
      " |-- previous: double (nullable = true)\n",
      " |-- poutcome: string (nullable = true)\n",
      " |-- Approved_no_yes: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Another way to check the data type of each attribute\n",
    "\n",
    "Hint: Use dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('age', 'int'),\n",
       " ('job', 'string'),\n",
       " ('marital_status', 'string'),\n",
       " ('education', 'string'),\n",
       " ('default', 'string'),\n",
       " ('balance', 'double'),\n",
       " ('housing', 'string'),\n",
       " ('loan', 'string'),\n",
       " ('contact', 'string'),\n",
       " ('day', 'int'),\n",
       " ('month', 'string'),\n",
       " ('duration', 'double'),\n",
       " ('campaign', 'double'),\n",
       " ('pdays', 'double'),\n",
       " ('previous', 'double'),\n",
       " ('poutcome', 'string'),\n",
       " ('Approved_no_yes', 'string')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Total number of Columns and Records\n",
    "\n",
    "Hint: Use columns and count() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of Columns = 17\n",
      "No. of Records = 4521\n"
     ]
    }
   ],
   "source": [
    "print(\"No. of Columns = {}\".format(len(data.columns)))\n",
    "\n",
    "print('No. of Records = {}'.format(data.count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Look at first 3 row of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(age=30, job=u'unemployed', marital_status=u'married', education=u'primary', default=u'no', balance=1787.0, housing=u'no', loan=u'no', contact=u'cellular', day=19, month=u'oct', duration=79.0, campaign=1.0, pdays=-1.0, previous=0.0, poutcome=u'unknown', Approved_no_yes=u'no'),\n",
       " Row(age=33, job=u'services', marital_status=u'married', education=u'secondary', default=u'no', balance=4789.0, housing=u'yes', loan=u'yes', contact=u'cellular', day=11, month=u'may', duration=220.0, campaign=1.0, pdays=339.0, previous=4.0, poutcome=u'failure', Approved_no_yes=u'no'),\n",
       " Row(age=35, job=u'management', marital_status=u'single', education=u'tertiary', default=u'no', balance=1350.0, housing=u'yes', loan=u'no', contact=u'cellular', day=16, month=u'apr', duration=185.0, campaign=1.0, pdays=330.0, previous=1.0, poutcome=u'failure', Approved_no_yes=u'no'),\n",
       " Row(age=30, job=u'management', marital_status=u'married', education=u'tertiary', default=u'no', balance=1476.0, housing=u'yes', loan=u'yes', contact=u'unknown', day=3, month=u'jun', duration=199.0, campaign=4.0, pdays=-1.0, previous=0.0, poutcome=u'unknown', Approved_no_yes=u'no'),\n",
       " Row(age=59, job=u'blue-collar', marital_status=u'married', education=u'secondary', default=u'no', balance=0.0, housing=u'yes', loan=u'no', contact=u'unknown', day=5, month=u'may', duration=226.0, campaign=1.0, pdays=-1.0, previous=0.0, poutcome=u'unknown', Approved_no_yes=u'no')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hint: Use Show() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+--------------+---------+-------+-------+-------+----+--------+---+-----+--------+--------+-----+--------+--------+---------------+\n",
      "|age|job       |marital_status|education|default|balance|housing|loan|contact |day|month|duration|campaign|pdays|previous|poutcome|Approved_no_yes|\n",
      "+---+----------+--------------+---------+-------+-------+-------+----+--------+---+-----+--------+--------+-----+--------+--------+---------------+\n",
      "|30 |unemployed|married       |primary  |no     |1787.0 |no     |no  |cellular|19 |oct  |79.0    |1.0     |-1.0 |0.0     |unknown |no             |\n",
      "|33 |services  |married       |secondary|no     |4789.0 |yes    |yes |cellular|11 |may  |220.0   |1.0     |339.0|4.0     |failure |no             |\n",
      "|35 |management|single        |tertiary |no     |1350.0 |yes    |no  |cellular|16 |apr  |185.0   |1.0     |330.0|1.0     |failure |no             |\n",
      "+---+----------+--------------+---------+-------+-------+-------+----+--------+---+-----+--------+--------+-----+--------+--------+---------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show(3,truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary statistics\n",
    "\n",
    "Hint: Use describe() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+-------+--------------+---------+-------+------------------+-------+----+--------+------------------+-----+------------------+------------------+------------------+------------------+--------+---------------+\n",
      "|summary|age               |job    |marital_status|education|default|balance           |housing|loan|contact |day               |month|duration          |campaign          |pdays             |previous          |poutcome|Approved_no_yes|\n",
      "+-------+------------------+-------+--------------+---------+-------+------------------+-------+----+--------+------------------+-----+------------------+------------------+------------------+------------------+--------+---------------+\n",
      "|count  |4521              |4521   |4521          |4521     |4521   |4521              |4521   |4521|4521    |4521              |4521 |4521              |4521              |4521              |4521              |4521    |4521           |\n",
      "|mean   |41.17009511170095 |null   |null          |null     |null   |1422.6578190665782|null   |null|null    |15.915284229152842|null |263.96129174961294|2.793629727936297 |39.766644547666445|0.5425790754257908|null    |null           |\n",
      "|stddev |10.576210958711263|null   |null          |null     |null   |3009.6381424673395|null   |null|null    |8.247667327229934 |null |259.85663262468216|3.1098066601885823|100.12112444301656|1.6935623506071211|null    |null           |\n",
      "|min    |19                |admin. |divorced      |primary  |no     |-3313.0           |no     |no  |cellular|1                 |apr  |4.0               |1.0               |-1.0              |0.0               |failure |no             |\n",
      "|max    |87                |unknown|single        |unknown  |yes    |71188.0           |yes    |yes |unknown |31                |sep  |3025.0            |50.0              |871.0             |25.0              |unknown |yes            |\n",
      "+-------+------------------+-------+--------------+---------+-------+------------------+-------+----+--------+------------------+-----+------------------+------------------+------------------+------------------+--------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.describe().show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show only fixed set of colums "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+----+------------------+------------------+\n",
      "|summary|               age|loan|           balance|             pdays|\n",
      "+-------+------------------+----+------------------+------------------+\n",
      "|  count|              4521|4521|              4521|              4521|\n",
      "|   mean| 41.17009511170095|null|1422.6578190665782|39.766644547666445|\n",
      "| stddev|10.576210958711263|null|3009.6381424673395|100.12112444301656|\n",
      "|    min|                19|  no|           -3313.0|              -1.0|\n",
      "|    max|                87| yes|           71188.0|             871.0|\n",
      "+-------+------------------+----+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.describe().select('summary', 'age', 'loan', 'balance', 'pdays').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation\n",
    "\n",
    "    Balance has -ve values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count the number of records that have balance < 0\n",
    "\n",
    "Hint: Use Where() and count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "366"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.where(data.balance < 0).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Replace negative balances with zeroes\n",
    "\n",
    "Hint: Use withColumn() and when() functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.withColumn('balance', when(data.balance > 0, data.balance).otherwise(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.where(data.balance < 0).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Handling missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking for null values at each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+--------------+---------+-------+-------+-------+----+-------+---+-----+--------+--------+-----+--------+--------+---------------+\n",
      "|age|job|marital_status|education|default|balance|housing|loan|contact|day|month|duration|campaign|pdays|previous|poutcome|Approved_no_yes|\n",
      "+---+---+--------------+---------+-------+-------+-------+----+-------+---+-----+--------+--------+-----+--------+--------+---------------+\n",
      "|  0|  0|             0|        0|      0|      0|      0|   0|      0|  0|    0|       0|       0|    0|       0|       0|              0|\n",
      "+---+---+--------------+---------+-------+-------+-------+----+-------+---+-----+--------+--------+-----+--------+--------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in data.columns]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split the data into training and test sets (30% held out for testing)\n",
    "\n",
    "Hint: randomSplit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "(trainingData, testData) = data.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating a list of categorical and numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_Var_Names = ['job', 'marital_status', 'education', 'default', 'housing', \n",
    "                 'day', 'contact', 'month', 'poutcome', 'Approved_no_yes']\n",
    "\n",
    "num_Var_Names = ['age', 'balance', 'duration', 'previous', 'pdays', 'campaign']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use VectorAssembler to combine a given list of numcolumns into a single vector column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "assembler_Num = VectorAssembler(inputCols=num_Var_Names, outputCol=\"num_features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scale all the numeric attributes using MinMaxScaler\n",
    "\n",
    "    MinMaxScaler transforms a dataset of Vector rows, rescaling each feature to a specific range (often [0, 1]). \n",
    "\n",
    "    MinMaxScaler computes summary statistics on a data set and produces a MinMaxScalerModel. The model can then transform each feature individually such that it is in the given range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import MinMaxScaler\n",
    "\n",
    "min_Max_Scalar = MinMaxScaler(inputCol=\"num_features\", outputCol=\"scaled_num_features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Covert categorical to numeric : \n",
    "\n",
    "    OneHotEncoder, StringIndexer, VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorAssembler\n",
    "\n",
    "indexers_Cat = [StringIndexer(inputCol=cat_Var_Name, outputCol=\"{0}_index\".format(cat_Var_Name)) for cat_Var_Name in cat_Var_Names ]\n",
    "encoders_Cat = [OneHotEncoder(inputCol=indexer.getOutputCol(), outputCol=\"{0}_vec\".format(indexer.getInputCol())) for indexer in indexers_Cat]\n",
    "assembler_Cat = VectorAssembler(inputCols=[encoder.getOutputCol() for encoder in encoders_Cat], outputCol=\"cat_features\")\n",
    "\n",
    "assembler = VectorAssembler(inputCols=[\"scaled_num_features\", \"cat_features\"], outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexer_Label = StringIndexer(inputCol=\"loan\", outputCol=\"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessiong_Stages = [assembler_Num]+[min_Max_Scalar]+indexers_Cat+encoders_Cat+[assembler_Cat]+[assembler]+[indexer_Label]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Building and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(maxIter=10, labelCol=\"label\", featuresCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "\n",
    "lr_Pipeline = Pipeline(stages=preprocessiong_Stages+[lr]) \n",
    "\n",
    "lr_Pipeline_model = lr_Pipeline.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [-0.5963868876433457,-3.378328735522387,0.6039853685796743,0.8866158657449871,-0.17195558187739077,-0.7561867347208221,0.11173336771337793,0.1634389598041522,0.1807245737590987,0.20575477529800748,0.09025213497059081,0.06469541845271566,-0.12409528244449289,0.30687445371617217,-0.6606379261833359,-0.5328248390760031,-2.0840361953512794,-0.029304167537653025,-0.2632028356412946,0.41010522113183917,0.12722000863999117,0.12917942036452706,-1.2623345190131554,-0.0852756052200935,-0.41493665772506494,0.01071603538506552,-0.1622178293121234,-0.1436119941095217,0.16782239723158107,-0.27826044654220994,0.08266833464435934,0.039251496095083695,0.38917368149690207,-0.06152875865570056,0.21610758173593156,0.7460246637970207,-0.07247484585569386,-0.24603860397765295,0.39872225340551215,0.2684296829831162,-0.24045029935331255,-0.17024330225837556,-0.7925310055910332,0.09078433068761876,0.3576991592994994,0.6636967986862286,-0.21641191324871345,0.1628438712686801,0.33889760212783687,-1.9460787324369697,1.0388503680208871,-0.7043932440335814,0.26949313722461393,0.10316510359143774,0.07593977637689335,0.34873226878751823,-0.23143901455723576,0.9802931294159074,-0.29881882130355414,-0.2766311658031326,0.7174655256668827,-0.15877153372366587,0.11049971755783022,-0.162293632366395,-0.7323436867760332,-1.242953533562362,-1.9245236288494565,0.17617441277154294,0.31672985686256866,-0.2631133329841699,0.8027609299317567]\n",
      "Intercept: -1.72668407657\n"
     ]
    }
   ],
   "source": [
    "print(\"Coefficients: \" + str(lr_Pipeline_model.stages[-1].coefficients))\n",
    "print(\"Intercept: \" + str(lr_Pipeline_model.stages[-1].intercept))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objectiveHistory:\n",
      "0.421742673039\n",
      "0.400940503001\n",
      "0.392598752525\n",
      "0.392163956628\n",
      "0.390765216398\n",
      "0.38868545325\n",
      "0.386363759066\n",
      "0.384704427528\n",
      "0.384115056589\n",
      "0.383810840052\n",
      "0.383260946092\n"
     ]
    }
   ],
   "source": [
    "lr_Summary = lr_Pipeline_model.stages[-1].summary\n",
    "objectiveHistory = lr_Summary.objectiveHistory\n",
    "print(\"objectiveHistory:\")\n",
    "for objective in objectiveHistory:\n",
    "    print(objective)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predictions_lr = lr_Pipeline_model.transform(trainingData)\n",
    "test_predictions_lr = lr_Pipeline_model.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+--------------+---------+-------+-------+-------+----+--------+---+-----+--------+--------+-----+--------+--------+---------------+-------------------------------+-----------------------------------------------------------+---------+--------------------+---------------+-------------+-------------+---------+-------------+-----------+--------------+---------------------+---------------+------------------+-------------+-------------+-----------+---------------+-------------+--------------+-------------+-------------------+----------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------+-----+----------------------------------------+-----------------------------------------+----------+\n",
      "|age|job    |marital_status|education|default|balance|housing|loan|contact |day|month|duration|campaign|pdays|previous|poutcome|Approved_no_yes|num_features                   |scaled_num_features                                        |job_index|marital_status_index|education_index|default_index|housing_index|day_index|contact_index|month_index|poutcome_index|Approved_no_yes_index|job_vec        |marital_status_vec|education_vec|default_vec  |housing_vec|day_vec        |contact_vec  |month_vec     |poutcome_vec |Approved_no_yes_vec|cat_features                                                    |features                                                                                                      |label|rawPrediction                           |probability                              |prediction|\n",
      "+---+-------+--------------+---------+-------+-------+-------+----+--------+---+-----+--------+--------+-----+--------+--------+---------------+-------------------------------+-----------------------------------------------------------+---------+--------------------+---------------+-------------+-------------+---------+-------------+-----------+--------------+---------------------+---------------+------------------+-------------+-------------+-----------+---------------+-------------+--------------+-------------+-------------------+----------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------+-----+----------------------------------------+-----------------------------------------+----------+\n",
      "|19 |student|single        |secondary|no     |302.0  |no     |no  |cellular|16 |jul  |205.0   |1.0     |-1.0 |0.0     |unknown |yes            |[19.0,302.0,205.0,0.0,-1.0,1.0]|[0.0,0.00718278035438221,0.07269439421338156,0.0,0.0,0.0]  |10.0     |1.0                 |0.0            |0.0          |1.0          |15.0     |0.0          |1.0        |0.0           |1.0                  |(11,[10],[1.0])|(2,[1],[1.0])     |(3,[0],[1.0])|(1,[0],[1.0])|(1,[],[])  |(30,[15],[1.0])|(2,[0],[1.0])|(11,[1],[1.0])|(3,[0],[1.0])|(1,[],[])          |(65,[10,12,13,16,33,48,51,61],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])|(71,[1,2,16,18,19,22,39,54,57,67],[0.00718278035438221,0.07269439421338156,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])  |0.0  |[3.4056748466850975,-3.4056748466850975]|[0.9678814183150274,0.0321185816849726]  |0.0       |\n",
      "|19 |student|single        |unknown  |no     |0.0    |no     |no  |cellular|11 |feb  |123.0   |3.0     |-1.0 |0.0     |unknown |no             |[19.0,0.0,123.0,0.0,-1.0,3.0]  |[0.0,0.0,0.043037974683544304,0.0,0.0,0.046511627906976744]|10.0     |1.0                 |3.0            |0.0          |1.0          |17.0     |0.0          |6.0        |0.0           |0.0                  |(11,[10],[1.0])|(2,[1],[1.0])     |(3,[],[])    |(1,[0],[1.0])|(1,[],[])  |(30,[17],[1.0])|(2,[0],[1.0])|(11,[6],[1.0])|(3,[0],[1.0])|(1,[0],[1.0])      |(65,[10,12,16,35,48,56,61,64],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])|(71,[2,5,16,18,22,41,54,62,67,70],[0.043037974683544304,0.046511627906976744,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])|0.0  |[4.350303261226603,-4.350303261226603]  |[0.9872614649929811,0.012738535007019026]|0.0       |\n",
      "+---+-------+--------------+---------+-------+-------+-------+----+--------+---+-----+--------+--------+-----+--------+--------+---------------+-------------------------------+-----------------------------------------------------------+---------+--------------------+---------------+-------------+-------------+---------+-------------+-----------+--------------+---------------------+---------------+------------------+-------------+-------------+-----------+---------------+-------------+--------------+-------------+-------------------+----------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------+-----+----------------------------------------+-----------------------------------------+----------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_predictions_lr.show(2,truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation : LR Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy  = 0.855961844197\n",
      "Test accuracy = 0.834302325581\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "\n",
    "predictionAndLabels_train_lr = train_predictions_lr.select(\"prediction\", \"label\")\n",
    "train_accuracy_lr = evaluator.evaluate(predictionAndLabels_train_lr)\n",
    "\n",
    "print(\"Train accuracy  = \" + str(train_accuracy_lr))\n",
    "\n",
    "predictionAndLabels_test_lr = test_predictions_lr.select(\"prediction\", \"label\")\n",
    "test_accuracy_lr = evaluator.evaluate(predictionAndLabels_test_lr)\n",
    "\n",
    "print(\"Test accuracy = \" + str(test_accuracy_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tuning LR Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "paramGrid = ParamGridBuilder()\\\n",
    "    .addGrid(lr.regParam, [0.1]) \\\n",
    "    .addGrid(lr.elasticNetParam, [0.5])\\\n",
    "    .build()\n",
    "    \n",
    "lr_crossval = CrossValidator(estimator=lr_Pipeline,\n",
    "                             estimatorParamMaps=paramGrid,\n",
    "                             evaluator=evaluator,\n",
    "                             numFolds=2)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run cross-validation, and choose the best set of parameters.\n",
    "lr_crossval_Model = lr_crossval.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predictions_lrcv = lr_crossval_Model.transform(trainingData)\n",
    "test_predictions_lrcv = lr_crossval_Model.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set accuracy  = 0.850556438792\n",
      "Test set accuracy = 0.839389534884\n"
     ]
    }
   ],
   "source": [
    "predictionAndLabels_train_lrcv = train_predictions_lrcv.select(\"prediction\", \"label\")\n",
    "train_accuracycv = evaluator.evaluate(predictionAndLabels_train_lrcv)\n",
    "print(\"Train set accuracy  = \" + str(train_accuracycv))\n",
    "\n",
    "predictionAndLabels_test_lrcv = test_predictions_lrcv.select(\"prediction\", \"label\")\n",
    "test_accuracycv = evaluator.evaluate(predictionAndLabels_test_lrcv)\n",
    "print(\"Test set accuracy = \" + str(test_accuracycv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "\n",
    "dt = DecisionTreeClassifier(labelCol=\"label\", featuresCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_Pipeline = Pipeline(stages=preprocessiong_Stages+[dt]) \n",
    "\n",
    "dt_Pipeline_model = dt_Pipeline.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predictions_dt = dt_Pipeline_model.transform(trainingData)\n",
    "test_predictions_dt = dt_Pipeline_model.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+--------------+---------+-------+-------+-------+----+--------+---+-----+--------+--------+-----+--------+--------+---------------+--------------------+--------------------+---------+--------------------+---------------+-------------+-------------+---------+-------------+-----------+--------------+---------------------+---------------+------------------+-------------+-------------+-----------+---------------+-------------+--------------+-------------+-------------------+--------------------+--------------------+-----+-------------+--------------------+----------+\n",
      "|age|    job|marital_status|education|default|balance|housing|loan| contact|day|month|duration|campaign|pdays|previous|poutcome|Approved_no_yes|        num_features| scaled_num_features|job_index|marital_status_index|education_index|default_index|housing_index|day_index|contact_index|month_index|poutcome_index|Approved_no_yes_index|        job_vec|marital_status_vec|education_vec|  default_vec|housing_vec|        day_vec|  contact_vec|     month_vec| poutcome_vec|Approved_no_yes_vec|        cat_features|            features|label|rawPrediction|         probability|prediction|\n",
      "+---+-------+--------------+---------+-------+-------+-------+----+--------+---+-----+--------+--------+-----+--------+--------+---------------+--------------------+--------------------+---------+--------------------+---------------+-------------+-------------+---------+-------------+-----------+--------------+---------------------+---------------+------------------+-------------+-------------+-----------+---------------+-------------+--------------+-------------+-------------------+--------------------+--------------------+-----+-------------+--------------------+----------+\n",
      "| 19|student|        single|secondary|     no|  302.0|     no|  no|cellular| 16|  jul|   205.0|     1.0| -1.0|     0.0| unknown|            yes|[19.0,302.0,205.0...|[0.0,0.0071827803...|     10.0|                 1.0|            0.0|          0.0|          1.0|     15.0|          0.0|        1.0|           0.0|                  1.0|(11,[10],[1.0])|     (2,[1],[1.0])|(3,[0],[1.0])|(1,[0],[1.0])|  (1,[],[])|(30,[15],[1.0])|(2,[0],[1.0])|(11,[1],[1.0])|(3,[0],[1.0])|          (1,[],[])|(65,[10,12,13,16,...|(71,[1,2,16,18,19...|  0.0|  [92.0,86.0]|[0.51685393258426...|       0.0|\n",
      "| 19|student|        single|  unknown|     no|    0.0|     no|  no|cellular| 11|  feb|   123.0|     3.0| -1.0|     0.0| unknown|             no|[19.0,0.0,123.0,0...|[0.0,0.0,0.043037...|     10.0|                 1.0|            3.0|          0.0|          1.0|     17.0|          0.0|        6.0|           0.0|                  0.0|(11,[10],[1.0])|     (2,[1],[1.0])|    (3,[],[])|(1,[0],[1.0])|  (1,[],[])|(30,[17],[1.0])|(2,[0],[1.0])|(11,[6],[1.0])|(3,[0],[1.0])|      (1,[0],[1.0])|(65,[10,12,16,35,...|(71,[2,5,16,18,22...|  0.0| [583.0,45.0]|[0.92834394904458...|       0.0|\n",
      "+---+-------+--------------+---------+-------+-------+-------+----+--------+---+-----+--------+--------+-----+--------+--------+---------------+--------------------+--------------------+---------+--------------------+---------------+-------------+-------------+---------+-------------+-----------+--------------+---------------------+---------------+------------------+-------------+-------------+-----------+---------------+-------------+--------------+-------------+-------------------+--------------------+--------------------+-----+-------------+--------------------+----------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_predictions_dt.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation : DT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy  = 0.857551669316\n",
      "Test accuracy = 0.839389534884\n"
     ]
    }
   ],
   "source": [
    "predictionAndLabels_train_dt = train_predictions_dt.select(\"prediction\", \"label\")\n",
    "train_accuracy_dt = evaluator.evaluate(predictionAndLabels_train_dt)\n",
    "\n",
    "print(\"Train accuracy  = \" + str(train_accuracy_dt))\n",
    "\n",
    "predictionAndLabels_test_dt = test_predictions_dt.select(\"prediction\", \"label\")\n",
    "test_accuracy_dt = evaluator.evaluate(predictionAndLabels_test_dt)\n",
    "\n",
    "print(\"Test accuracy = \" + str(test_accuracy_dt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tuning DT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "paramGridDT = ParamGridBuilder()\\\n",
    "    .addGrid(dt.maxDepth, [1,6,10]) \\\n",
    "    .build()\n",
    "    \n",
    "dt_crossval = CrossValidator(estimator=dt_Pipeline,\n",
    "                             estimatorParamMaps=paramGridDT,\n",
    "                             evaluator=evaluator,\n",
    "                             numFolds=2)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run cross-validation, and choose the best set of parameters.\n",
    "dt_crossval_Model = dt_crossval.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predictions_dtcv = dt_crossval_Model.transform(trainingData)\n",
    "test_predictions_dtcv = dt_crossval_Model.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set accuracy  = 0.850556438792\n",
      "Test set accuracy = 0.839389534884\n"
     ]
    }
   ],
   "source": [
    "predictionAndLabels_train_dtcv = train_predictions_dtcv.select(\"prediction\", \"label\")\n",
    "train_accuracydtcv = evaluator.evaluate(predictionAndLabels_train_dtcv)\n",
    "print(\"Train set accuracy  = \" + str(train_accuracydtcv))\n",
    "\n",
    "predictionAndLabels_test_dtcv = test_predictions_dtcv.select(\"prediction\", \"label\")\n",
    "test_accuracydtcv = evaluator.evaluate(predictionAndLabels_test_dtcv)\n",
    "print(\"Test set accuracy = \" + str(test_accuracydtcv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_Pipeline = Pipeline(stages=preprocessiong_Stages+[rf]) \n",
    "\n",
    "rf_Pipeline_model = rf_Pipeline.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predictions_rf = rf_Pipeline_model.transform(trainingData)\n",
    "test_predictions_rf = rf_Pipeline_model.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+--------------+---------+-------+-------+-------+----+--------+---+-----+--------+--------+-----+--------+--------+---------------+--------------------+--------------------+---------+--------------------+---------------+-------------+-------------+---------+-------------+-----------+--------------+---------------------+---------------+------------------+-------------+-------------+-----------+---------------+-------------+--------------+-------------+-------------------+--------------------+--------------------+-----+--------------------+--------------------+----------+\n",
      "|age|    job|marital_status|education|default|balance|housing|loan| contact|day|month|duration|campaign|pdays|previous|poutcome|Approved_no_yes|        num_features| scaled_num_features|job_index|marital_status_index|education_index|default_index|housing_index|day_index|contact_index|month_index|poutcome_index|Approved_no_yes_index|        job_vec|marital_status_vec|education_vec|  default_vec|housing_vec|        day_vec|  contact_vec|     month_vec| poutcome_vec|Approved_no_yes_vec|        cat_features|            features|label|       rawPrediction|         probability|prediction|\n",
      "+---+-------+--------------+---------+-------+-------+-------+----+--------+---+-----+--------+--------+-----+--------+--------+---------------+--------------------+--------------------+---------+--------------------+---------------+-------------+-------------+---------+-------------+-----------+--------------+---------------------+---------------+------------------+-------------+-------------+-----------+---------------+-------------+--------------+-------------+-------------------+--------------------+--------------------+-----+--------------------+--------------------+----------+\n",
      "| 19|student|        single|secondary|     no|  302.0|     no|  no|cellular| 16|  jul|   205.0|     1.0| -1.0|     0.0| unknown|            yes|[19.0,302.0,205.0...|[0.0,0.0071827803...|     10.0|                 1.0|            0.0|          0.0|          1.0|     15.0|          0.0|        1.0|           0.0|                  1.0|(11,[10],[1.0])|     (2,[1],[1.0])|(3,[0],[1.0])|(1,[0],[1.0])|  (1,[],[])|(30,[15],[1.0])|(2,[0],[1.0])|(11,[1],[1.0])|(3,[0],[1.0])|          (1,[],[])|(65,[10,12,13,16,...|(71,[1,2,16,18,19...|  0.0|[15.2854402694631...|[0.76427201347315...|       0.0|\n",
      "| 19|student|        single|  unknown|     no|    0.0|     no|  no|cellular| 11|  feb|   123.0|     3.0| -1.0|     0.0| unknown|             no|[19.0,0.0,123.0,0...|[0.0,0.0,0.043037...|     10.0|                 1.0|            3.0|          0.0|          1.0|     17.0|          0.0|        6.0|           0.0|                  0.0|(11,[10],[1.0])|     (2,[1],[1.0])|    (3,[],[])|(1,[0],[1.0])|  (1,[],[])|(30,[17],[1.0])|(2,[0],[1.0])|(11,[6],[1.0])|(3,[0],[1.0])|      (1,[0],[1.0])|(65,[10,12,16,35,...|(71,[2,5,16,18,22...|  0.0|[17.4875041197362...|[0.87437520598681...|       0.0|\n",
      "+---+-------+--------------+---------+-------+-------+-------+----+--------+---+-----+--------+--------+-----+--------+--------+---------------+--------------------+--------------------+---------+--------------------+---------------+-------------+-------------+---------+-------------+-----------+--------------+---------------------+---------------+------------------+-------------+-------------+-----------+---------------+-------------+--------------+-------------+-------------------+--------------------+--------------------+-----+--------------------+--------------------+----------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_predictions_rf.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation : RF Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy  = 0.850556438792\n",
      "Test accuracy = 0.839389534884\n"
     ]
    }
   ],
   "source": [
    "predictionAndLabels_train_rf = train_predictions_rf.select(\"prediction\", \"label\")\n",
    "train_accuracy_rf = evaluator.evaluate(predictionAndLabels_train_rf)\n",
    "\n",
    "print(\"Train accuracy  = \" + str(train_accuracy_rf))\n",
    "\n",
    "predictionAndLabels_test_rf = test_predictions_rf.select(\"prediction\", \"label\")\n",
    "test_accuracy_rf = evaluator.evaluate(predictionAndLabels_test_rf)\n",
    "\n",
    "print(\"Test accuracy = \" + str(test_accuracy_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tuning RF Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "paramGridRF = ParamGridBuilder()\\\n",
    "            .addGrid(rf.maxDepth, [5])\\\n",
    "            .addGrid(rf.numTrees, [20])\\\n",
    "            .build()\n",
    "    \n",
    "rf_crossval = CrossValidator(estimator=rf_Pipeline,\n",
    "                             estimatorParamMaps=paramGridRF,\n",
    "                             evaluator=evaluator,\n",
    "                             numFolds=2)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run cross-validation, and choose the best set of parameters.\n",
    "rf_crossval_Model = rf_crossval.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predictions_rfcv = rf_crossval_Model.transform(trainingData)\n",
    "test_predictions_rfcv = rf_crossval_Model.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set accuracy  = 0.850556438792\n",
      "Test set accuracy = 0.839389534884\n"
     ]
    }
   ],
   "source": [
    "predictionAndLabels_train_rfcv = train_predictions_rfcv.select(\"prediction\", \"label\")\n",
    "train_accuracyrfcv = evaluator.evaluate(predictionAndLabels_train_rfcv)\n",
    "print(\"Train set accuracy  = \" + str(train_accuracyrfcv))\n",
    "\n",
    "predictionAndLabels_test_rfcv = test_predictions_rfcv.select(\"prediction\", \"label\")\n",
    "test_accuracyrfcv = evaluator.evaluate(predictionAndLabels_test_rfcv)\n",
    "print(\"Test set accuracy = \" + str(test_accuracyrfcv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient Boosted Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import GBTClassifier\n",
    "\n",
    "gbt = GBTClassifier(labelCol=\"label\", featuresCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbt_Pipeline = Pipeline(stages=preprocessiong_Stages+[gbt]) \n",
    "\n",
    "gbt_Pipeline_model = gbt_Pipeline.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predictions_gbt = gbt_Pipeline_model.transform(trainingData)\n",
    "test_predictions_gbt = gbt_Pipeline_model.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+--------------+---------+-------+-------+-------+----+--------+---+-----+--------+--------+-----+--------+--------+---------------+--------------------+--------------------+---------+--------------------+---------------+-------------+-------------+---------+-------------+-----------+--------------+---------------------+---------------+------------------+-------------+-------------+-----------+---------------+-------------+--------------+-------------+-------------------+--------------------+--------------------+-----+--------------------+--------------------+----------+\n",
      "|age|    job|marital_status|education|default|balance|housing|loan| contact|day|month|duration|campaign|pdays|previous|poutcome|Approved_no_yes|        num_features| scaled_num_features|job_index|marital_status_index|education_index|default_index|housing_index|day_index|contact_index|month_index|poutcome_index|Approved_no_yes_index|        job_vec|marital_status_vec|education_vec|  default_vec|housing_vec|        day_vec|  contact_vec|     month_vec| poutcome_vec|Approved_no_yes_vec|        cat_features|            features|label|       rawPrediction|         probability|prediction|\n",
      "+---+-------+--------------+---------+-------+-------+-------+----+--------+---+-----+--------+--------+-----+--------+--------+---------------+--------------------+--------------------+---------+--------------------+---------------+-------------+-------------+---------+-------------+-----------+--------------+---------------------+---------------+------------------+-------------+-------------+-----------+---------------+-------------+--------------+-------------+-------------------+--------------------+--------------------+-----+--------------------+--------------------+----------+\n",
      "| 19|student|        single|secondary|     no|  302.0|     no|  no|cellular| 16|  jul|   205.0|     1.0| -1.0|     0.0| unknown|            yes|[19.0,302.0,205.0...|[0.0,0.0071827803...|     10.0|                 1.0|            0.0|          0.0|          1.0|     15.0|          0.0|        1.0|           0.0|                  1.0|(11,[10],[1.0])|     (2,[1],[1.0])|(3,[0],[1.0])|(1,[0],[1.0])|  (1,[],[])|(30,[15],[1.0])|(2,[0],[1.0])|(11,[1],[1.0])|(3,[0],[1.0])|          (1,[],[])|(65,[10,12,13,16,...|(71,[1,2,16,18,19...|  0.0|[0.68595223561334...|[0.79768767528843...|       0.0|\n",
      "| 19|student|        single|  unknown|     no|    0.0|     no|  no|cellular| 11|  feb|   123.0|     3.0| -1.0|     0.0| unknown|             no|[19.0,0.0,123.0,0...|[0.0,0.0,0.043037...|     10.0|                 1.0|            3.0|          0.0|          1.0|     17.0|          0.0|        6.0|           0.0|                  0.0|(11,[10],[1.0])|     (2,[1],[1.0])|    (3,[],[])|(1,[0],[1.0])|  (1,[],[])|(30,[17],[1.0])|(2,[0],[1.0])|(11,[6],[1.0])|(3,[0],[1.0])|      (1,[0],[1.0])|(65,[10,12,16,35,...|(71,[2,5,16,18,22...|  0.0|[1.31364537967406...|[0.93259744750443...|       0.0|\n",
      "+---+-------+--------------+---------+-------+-------+-------+----+--------+---+-----+--------+--------+-----+--------+--------+---------------+--------------------+--------------------+---------+--------------------+---------------+-------------+-------------+---------+-------------+-----------+--------------+---------------------+---------------+------------------+-------------+-------------+-----------+---------------+-------------+--------------+-------------+-------------------+--------------------+--------------------+-----+--------------------+--------------------+----------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_predictions_gbt.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation : gbt Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy  = 0.873767885533\n",
      "Test accuracy = 0.842296511628\n"
     ]
    }
   ],
   "source": [
    "predictionAndLabels_train_gbt = train_predictions_gbt.select(\"prediction\", \"label\")\n",
    "train_accuracy_gbt = evaluator.evaluate(predictionAndLabels_train_gbt)\n",
    "\n",
    "print(\"Train accuracy  = \" + str(train_accuracy_gbt))\n",
    "\n",
    "predictionAndLabels_test_gbt = test_predictions_gbt.select(\"prediction\", \"label\")\n",
    "test_accuracy_gbt = evaluator.evaluate(predictionAndLabels_test_gbt)\n",
    "\n",
    "print(\"Test accuracy = \" + str(test_accuracy_gbt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tuning GBT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "paramGridGBT = ParamGridBuilder()\\\n",
    "            .addGrid(gbt.maxDepth, [5])\\\n",
    "            .addGrid(gbt.maxIter, [20])\\\n",
    "            .addGrid(gbt.stepSize, [0.1])\\\n",
    "            .build()\n",
    "    \n",
    "gbt_crossval = CrossValidator(estimator=gbt_Pipeline,\n",
    "                             estimatorParamMaps=paramGridGBT,\n",
    "                             evaluator=evaluator,\n",
    "                             numFolds=2)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run cross-validation, and choose the best set of parameters.\n",
    "gbt_crossval_Model = gbt_crossval.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predictions_gbtcv = gbt_crossval_Model.transform(trainingData)\n",
    "test_predictions_gbtcv = gbt_crossval_Model.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set accuracy  = 0.873767885533\n",
      "Test set accuracy = 0.842296511628\n"
     ]
    }
   ],
   "source": [
    "predictionAndLabels_train_gbtcv = train_predictions_gbtcv.select(\"prediction\", \"label\")\n",
    "train_accuracygbtcv = evaluator.evaluate(predictionAndLabels_train_gbtcv)\n",
    "print(\"Train set accuracy  = \" + str(train_accuracygbtcv))\n",
    "\n",
    "predictionAndLabels_test_gbtcv = test_predictions_gbtcv.select(\"prediction\", \"label\")\n",
    "test_accuracygbtcv = evaluator.evaluate(predictionAndLabels_test_gbtcv)\n",
    "print(\"Test set accuracy = \" + str(test_accuracygbtcv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
