{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Create the Spark Env 2M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "os.environ[\"SPARK_HOME\"] = \"/usr/hdp/current/spark2-client\"\n",
    "os.environ[\"PYLIB\"] = os.environ[\"SPARK_HOME\"] + \"/python/lib\"\n",
    "sys.path.insert(0, os.environ[\"PYLIB\"] + \"/py4j-0.10.6-src.zip\")\n",
    "sys.path.insert(0, os.environ[\"PYLIB\"] + \"/pyspark.zip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Load the required Libraries 2M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.conf import SparkConf\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover, CountVectorizer, IDF, StringIndexer, IndexToString, StringIndexerModel\n",
    "from pyspark.ml.classification import NaiveBayes\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.ml import PipelineModel\n",
    "from itertools import chain\n",
    "from pyspark.sql.functions import create_map, lit\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from IPython.core.display import display, HTML\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(333)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Create the Spark Configuration and set the Master and Appname 2M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = SparkConf().setAppName(\"big_data_phd_2618\").setMaster('local[*]')\n",
    "sc = SparkContext(conf=conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Create the Spark Session 2M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://d.insofe.edu.in:4042\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.3.0.2.6.5.0-292</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>big_data_phd_2618</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x23c9f10>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Create the function to get the list of the filepaths in a directory in plain Python 5M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_file_list(path):\n",
    "    '''\n",
    "    Arguments : path of the directory in linux format (Ex :'/home/username/directory')\n",
    "    Return : List of files in the directory as file_list (Ex:'file:///home/username/phd/alt')\n",
    "    '''\n",
    "    file_list = [os.path.join(\"file://\"+path, file) for file in os.listdir(path)]\n",
    "    return file_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.  Read the text data in each directory separtely as a spark data frame using read.text 5M\n",
    "#### Read the data from local only do not move the data to HDFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path_root = \"/home/2618B56/BigData_PHD/\"\n",
    "path_root = \"/home/datasets/PHD_Dataset/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_alt = spark.read.text(create_file_list(path_root+\"Train/alt\"),  wholetext=True)\n",
    "df_comp = spark.read.text(create_file_list(path_root+\"Train/comp\"),  wholetext=True)\n",
    "df_misc = spark.read.text(create_file_list(path_root+\"Train/misc\"),  wholetext=True)\n",
    "df_rec = spark.read.text(create_file_list(path_root+\"Train/rec\"),  wholetext=True)\n",
    "df_sci = spark.read.text(create_file_list(path_root+\"Train/sci\"),  wholetext=True)\n",
    "df_soc = spark.read.text(create_file_list(path_root+\"Train/soc\"),  wholetext=True)\n",
    "df_talk = spark.read.text(create_file_list(path_root+\"Train/talk\"),  wholetext=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "585"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_misc.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Create the lable for the Data frames (*Hint : use withColumn and expr using repeat) 4M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_alt_labeled = df_alt.withColumn(\"target_label\", F.lit('alt'))\n",
    "df_comp_labeled = df_comp.withColumn(\"target_label\", F.lit('comp'))\n",
    "df_misc_labeled = df_misc.withColumn(\"target_label\", F.lit('misc'))\n",
    "df_rec_labeled = df_rec.withColumn(\"target_label\", F.lit('rec'))\n",
    "df_sci_labeled = df_sci.withColumn(\"target_label\", F.lit('sci'))\n",
    "df_soc_labeled = df_soc.withColumn(\"target_label\", F.lit('soc'))\n",
    "df_talk_labeled = df_talk.withColumn(\"target_label\", F.lit('talk'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Understand the below function and write the observation in MarkDown 2M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools \n",
    "\n",
    "def unionAll(list_of_dfs):\n",
    "    return functools.reduce(lambda df1,df2: df1.union(df2.select(df1.columns)), list_of_dfs) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function is used to do a row bind of two dataframes and club into one. \n",
    "\n",
    "Note, this operations requires the dataframes to have same column name.\n",
    "\n",
    "In the above implemenattion scenario, all seven dataframes will be joined into one row wise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the data frame for the entire data set using the above function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_with_label = unionAll([df_alt_labeled, df_comp_labeled, df_misc_labeled, df_rec_labeled, df_sci_labeled, df_soc_labeled, df_talk_labeled])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+\n",
      "|               value|target_label|\n",
      "+--------------------+------------+\n",
      "|The recent rise o...|         alt|\n",
      "|Archive-name: ath...|         alt|\n",
      "|Archive-name: ath...|         alt|\n",
      "|Archive-name: ath...|         alt|\n",
      "|Archive-name: ath...|         alt|\n",
      "|This kind of argu...|         alt|\n",
      "| \n",
      ": There are a c...|         alt|\n",
      "|: I\n",
      ": |> Jim,\n",
      ": |...|         alt|\n",
      "|\n",
      "True.  At first,...|         alt|\n",
      "|Archive-name: ath...|         alt|\n",
      "|\n",
      "\n",
      "You misrepresen...|         alt|\n",
      "|->\tFirst I want t...|         alt|\n",
      "|A new alternative...|         alt|\n",
      "|\n",
      "Size of armies, ...|         alt|\n",
      "|New in this versi...|         alt|\n",
      "|\n",
      "\n",
      "But you haven't...|         alt|\n",
      "|[why do babies ge...|         alt|\n",
      "|[deleted]\n",
      "think:\n",
      "...|         alt|\n",
      "|\n",
      "The number of ci...|         alt|\n",
      "|\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Okay... I ar...|         alt|\n",
      "+--------------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_final_with_label.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11314"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final_with_label.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9.Rename the Column value as News 2M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_with_label_renamed = df_final_with_label.withColumnRenamed(\"value\", \"News\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10. Display the first five rows in the data frame 2M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+\n",
      "|                News|target_label|\n",
      "+--------------------+------------+\n",
      "|The recent rise o...|         alt|\n",
      "|Archive-name: ath...|         alt|\n",
      "|Archive-name: ath...|         alt|\n",
      "|Archive-name: ath...|         alt|\n",
      "|Archive-name: ath...|         alt|\n",
      "+--------------------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_final_with_label_renamed.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11. Display the counts of classes in the label 2M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------------+\n",
      "|target_label|count_of_classes|\n",
      "+------------+----------------+\n",
      "|         soc|             599|\n",
      "|         alt|             480|\n",
      "|        talk|            1952|\n",
      "|         sci|            2373|\n",
      "|        misc|             585|\n",
      "|         rec|            2389|\n",
      "|        comp|            2936|\n",
      "+------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_final_with_label_renamed.groupBy('target_label').count().withColumnRenamed('count','count_of_classes').show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 12. Perform the preprocessing Steps required for the Text Data  ,Split the data into train and validation sets 10M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- News: string (nullable = true)\n",
      " |-- target_label: string (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_final_with_label_renamed.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data count : 7917\n",
      "Test data count : 3397\n"
     ]
    }
   ],
   "source": [
    "(trainingData, testData) = df_final_with_label_renamed.randomSplit([0.7, 0.3])\n",
    "print(\"Training data count : {}\".format(trainingData.count()))\n",
    "print(\"Test data count : {}\".format(testData.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingData_X = trainingData[['News']]\n",
    "trainingData_y = trainingData[['target_label']]\n",
    "\n",
    "\n",
    "testData_X = testData[['News']]\n",
    "testData_y = testData[['target_label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the News column\n",
    "tokenizer  = Tokenizer(inputCol = 'News',outputCol = 'with_stop_words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove stop words\n",
    "remover = StopWordsRemover(inputCol=\"with_stop_words\", outputCol=\"words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracts a vocabulary from document collections and generates a CountVectorizerModel.\n",
    "countvectorizer = CountVectorizer(inputCol = 'words' , outputCol = 'rawFeature')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the Inverse Document Frequency (IDF) given a collection of documents.\n",
    "idf = IDF(inputCol = 'rawFeature',outputCol = 'features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use StringIndexer top convert String target_label to num\n",
    "stringindexer = StringIndexer(inputCol = 'target_label' , outputCol = 'label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pre=processing flow\n",
    "preprocessing_Stages = [tokenizer]+[remover]+[countvectorizer]+[idf]+[stringindexer] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 13 .Build only the Naiveabayes Model 5M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_model = NaiveBayes(labelCol='label',featuresCol=\"features\")\n",
    "nb_Pipeline = Pipeline(stages=preprocessing_Stages + [nb_model]) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 14. Evaluate the model using the MulticlassClassification Evaluator 3M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", \n",
    "                                              predictionCol=\"prediction\",\n",
    "                                              metricName=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit the model with training data\n",
    "nb_crossval_Model = nb_Pipeline.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on training data\n",
    "predictions_train = nb_crossval_Model.transform(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|prediction|label|\n",
      "+----------+-----+\n",
      "|       6.0|  6.0|\n",
      "|       6.0|  6.0|\n",
      "|       6.0|  6.0|\n",
      "|       6.0|  6.0|\n",
      "|       6.0|  6.0|\n",
      "|       6.0|  6.0|\n",
      "|       6.0|  6.0|\n",
      "|       6.0|  6.0|\n",
      "|       6.0|  6.0|\n",
      "|       6.0|  6.0|\n",
      "+----------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions_train.select(\"prediction\", \"label\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on test data\n",
    "predictions_test = nb_crossval_Model.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|prediction|label|\n",
      "+----------+-----+\n",
      "|       6.0|  6.0|\n",
      "|       5.0|  6.0|\n",
      "|       6.0|  6.0|\n",
      "|       6.0|  6.0|\n",
      "|       6.0|  6.0|\n",
      "|       3.0|  6.0|\n",
      "|       6.0|  6.0|\n",
      "|       3.0|  6.0|\n",
      "|       6.0|  6.0|\n",
      "|       6.0|  6.0|\n",
      "+----------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions_test.select(\"prediction\", \"label\").show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 15. Print the accuracies and save the model 2M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9642541366679298"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.evaluate(predictions_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8118928466293789"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.evaluate(predictions_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model in hdfs\n",
    "nb_crossval_Model.save(\"/user/2618B56/big_data_phd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the model for testing on actual test data\n",
    "model_loaded = PipelineModel.load(\"/user/2618B56/big_data_phd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load actual test data\n",
    "df_test_dataset = spark.read.text(create_file_list(path_root+\"Test/\"),  wholetext=True).withColumnRenamed(\"value\", \"News\")\n",
    "df_test_dataset.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|                News|\n",
      "+--------------------+\n",
      "|\n",
      "Well, they never...|\n",
      "|\n",
      "\n",
      "  I am not a pa...|\n",
      "|I am writing this...|\n",
      "|Is anyone out the...|\n",
      "|Does any one know...|\n",
      "|A friend recorded...|\n",
      "|\n",
      "\n",
      "I would expect ...|\n",
      "|\n",
      "\n",
      "Okay, here's wh...|\n",
      "|Someone asked me ...|\n",
      "|\n",
      "Um, Kent... just...|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_test_dataset.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|                News|     with_stop_words|               words|          rawFeature|            features|       rawPrediction|         probability|prediction|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|\n",
      "Well, they never...|[, well,, they, n...|[, well,, never, ...|(148691,[0,6,10,1...|(148691,[0,6,10,1...|[-9977.1724783872...|[0.0,0.0,0.0,1.0,...|       3.0|\n",
      "|\n",
      "\n",
      "  I am not a pa...|[, , , , i, am, n...|[, , , , paranoid...|(148691,[0,4,6,11...|(148691,[0,4,6,11...|[-6898.7457826260...|[0.0,2.7689381950...|       3.0|\n",
      "|I am writing this...|[i, am, writing, ...|[writing, find, f...|(148691,[0,8,13,1...|(148691,[0,8,13,1...|[-4430.5886414145...|[6.06515916728927...|       1.0|\n",
      "|Is anyone out the...|[is, anyone, out,...|[anyone, knowledg...|(148691,[0,4,10,2...|(148691,[0,4,10,2...|[-2923.4286115139...|[9.09690000889191...|       3.0|\n",
      "|Does any one know...|[does, any, one, ...|[one, know, decen...|(148691,[0,2,3,7,...|(148691,[0,2,3,7,...|[-2691.2105466014...|[1.0,8.4746028722...|       0.0|\n",
      "|A friend recorded...|[a, friend, recor...|[friend, recorded...|(148691,[0,14,41,...|(148691,[0,14,41,...|[-2545.5053100543...|[6.62009756708638...|       3.0|\n",
      "|\n",
      "\n",
      "I would expect ...|[, , i, would, ex...|[, , expect, cd-r...|(148691,[0,11,17,...|(148691,[0,11,17,...|[-1667.7220214948...|[2.26271489587418...|       1.0|\n",
      "|\n",
      "\n",
      "Okay, here's wh...|[, , okay,, here'...|[, , okay,, do., ...|(148691,[0,8,39,4...|(148691,[0,8,39,4...|[-1921.3729390463...|[2.40635710054701...|       4.0|\n",
      "|Someone asked me ...|[someone, asked, ...|[someone, asked, ...|(148691,[0,4,35,4...|(148691,[0,4,35,4...|[-1338.8040014101...|[0.00526801016300...|       1.0|\n",
      "|\n",
      "Um, Kent... just...|[, um,, kent..., ...|[, um,, kent..., ...|(148691,[0,11809,...|(148691,[0,11809,...|[-160.41437023018...|[3.94698672173558...|       2.0|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predict using the above defined model\n",
    "pred_df_test = model_loaded.transform(df_test_dataset)\n",
    "pred_df_test.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+----------+\n",
      "|                News|         probability|prediction|\n",
      "+--------------------+--------------------+----------+\n",
      "|\n",
      "Well, they never...|[0.0,0.0,0.0,1.0,...|       3.0|\n",
      "|\n",
      "\n",
      "  I am not a pa...|[0.0,2.7689381950...|       3.0|\n",
      "|I am writing this...|[6.06515916728927...|       1.0|\n",
      "|Is anyone out the...|[9.09690000889191...|       3.0|\n",
      "|Does any one know...|[1.0,8.4746028722...|       0.0|\n",
      "|A friend recorded...|[6.62009756708638...|       3.0|\n",
      "|\n",
      "\n",
      "I would expect ...|[2.26271489587418...|       1.0|\n",
      "|\n",
      "\n",
      "Okay, here's wh...|[2.40635710054701...|       4.0|\n",
      "|Someone asked me ...|[0.00526801016300...|       1.0|\n",
      "|\n",
      "Um, Kent... just...|[3.94698672173558...|       2.0|\n",
      "+--------------------+--------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Look at required fields\n",
    "pred_df_test.select(\"News\",\"probability\",\"prediction\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 16. Get the actual labels for the indexed ones after you have created the predictions and print the head for the label and prediction for train and validation sets for atleast 6 records 2M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Tokenizer_444ea06fb8a34db0ec45,\n",
       " StopWordsRemover_48ed9c6c90820908de19,\n",
       " CountVectorizer_4e40aff9d9e88d540017,\n",
       " IDF_42919aa96d76def5a266,\n",
       " StringIndexer_46c987f5037159b1eb79,\n",
       " NaiveBayes_4efeabd2d361f99a89eb]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check all stages\n",
    "model_loaded.stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.ml.feature.StringIndexerModel"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract the StringIndexer Stage\n",
    "stringIndexerStage = [x for x in model_loaded.stages if isinstance(x, StringIndexerModel)][0]\n",
    "type(stringIndexerStage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+\n",
      "|target_label|label|\n",
      "+------------+-----+\n",
      "|        comp|  0.0|\n",
      "|         alt|  6.0|\n",
      "|         sci|  1.0|\n",
      "|        misc|  4.0|\n",
      "|         rec|  2.0|\n",
      "|         soc|  5.0|\n",
      "|        talk|  3.0|\n",
      "+------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check the actual label to index mapping\n",
    "actual_label_to_index_mapping = stringIndexerStage.transform(trainingData).select('target_label', 'label').distinct()\n",
    "actual_label_to_index_mapping.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.0: u'comp',\n",
       " 1.0: u'sci',\n",
       " 2.0: u'rec',\n",
       " 3.0: u'talk',\n",
       " 4.0: u'misc',\n",
       " 5.0: u'soc',\n",
       " 6.0: u'alt'}"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#actual_label_to_index_mapping_dict = \n",
    "list_actual_label_to_index_mapping = map(lambda row: row.asDict(), actual_label_to_index_mapping.collect())\n",
    "dict_actual_label_to_index_mapping = {mapping['label']: mapping['target_label'] for mapping in list_actual_label_to_index_mapping}\n",
    "dict_actual_label_to_index_mapping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+----------+\n",
      "|                News|         probability|prediction|\n",
      "+--------------------+--------------------+----------+\n",
      "|\n",
      "Well, they never...|[0.0,0.0,0.0,1.0,...|       3.0|\n",
      "|\n",
      "\n",
      "  I am not a pa...|[0.0,2.7689381950...|       3.0|\n",
      "|I am writing this...|[6.06515916728927...|       1.0|\n",
      "|Is anyone out the...|[9.09690000889191...|       3.0|\n",
      "|Does any one know...|[1.0,8.4746028722...|       0.0|\n",
      "|A friend recorded...|[6.62009756708638...|       3.0|\n",
      "|\n",
      "\n",
      "I would expect ...|[2.26271489587418...|       1.0|\n",
      "|\n",
      "\n",
      "Okay, here's wh...|[2.40635710054701...|       4.0|\n",
      "|Someone asked me ...|[0.00526801016300...|       1.0|\n",
      "|\n",
      "Um, Kent... just...|[3.94698672173558...|       2.0|\n",
      "+--------------------+--------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_df_test.select(\"News\",\"probability\",\"prediction\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+----------+----------------------+\n",
      "|                News|         probability|prediction|prediction_actual_name|\n",
      "+--------------------+--------------------+----------+----------------------+\n",
      "|\n",
      "Well, they never...|[0.0,0.0,0.0,1.0,...|       3.0|                  talk|\n",
      "|\n",
      "\n",
      "  I am not a pa...|[0.0,2.7689381950...|       3.0|                  talk|\n",
      "|I am writing this...|[6.06515916728927...|       1.0|                   sci|\n",
      "|Is anyone out the...|[9.09690000889191...|       3.0|                  talk|\n",
      "|Does any one know...|[1.0,8.4746028722...|       0.0|                  comp|\n",
      "|A friend recorded...|[6.62009756708638...|       3.0|                  talk|\n",
      "|\n",
      "\n",
      "I would expect ...|[2.26271489587418...|       1.0|                   sci|\n",
      "|\n",
      "\n",
      "Okay, here's wh...|[2.40635710054701...|       4.0|                  misc|\n",
      "|Someone asked me ...|[0.00526801016300...|       1.0|                   sci|\n",
      "|\n",
      "Um, Kent... just...|[3.94698672173558...|       2.0|                   rec|\n",
      "+--------------------+--------------------+----------+----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mapping_expr = create_map([lit(x) for x in chain(*dict_actual_label_to_index_mapping.items())])\n",
    "pred_df_test = pred_df_test.withColumn('prediction_actual_name', mapping_expr[pred_df_test['prediction']])\n",
    "pred_df_test.select(\"News\",\"probability\",\"prediction\", \"prediction_actual_name\").show(100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed indexed column 'label' back to original string column 'originalCategory' using labels in metadata\n",
      "+------------+-----+\n",
      "|target_label|label|\n",
      "+------------+-----+\n",
      "|        comp|  0.0|\n",
      "|         alt|  6.0|\n",
      "|         sci|  1.0|\n",
      "|        misc|  4.0|\n",
      "|         rec|  2.0|\n",
      "|         soc|  5.0|\n",
      "|        talk|  3.0|\n",
      "+------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "converter = IndexToString(inputCol=\"label\", outputCol=\"originalCategory\")\n",
    "converted = converter.transform(stringIndexerStage.transform(trainingData).select('target_label', 'label').distinct())\n",
    "\n",
    "print(\"Transformed indexed column '%s' back to original string column '%s' using \"\n",
    "      \"labels in metadata\" % (converter.getInputCol(), converter.getOutputCol()))\n",
    "converted.select(\"target_label\", \"label\").show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
